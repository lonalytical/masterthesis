@misc{alexanderrobitzsch[autcre]oliverluedtke[aut]MdmbModelBased2017,
  title = {Mdmb: {{Model Based Treatment}} of {{Missing Data}}},
  shorttitle = {Mdmb},
  author = {{Alexander Robitzsch [aut, cre], Oliver Luedtke [aut]}},
  year = 2017,
  month = jan,
  pages = {1.9-22},
  publisher = {Comprehensive R Archive Network},
  doi = {10.32614/CRAN.package.mdmb},
  urldate = {2025-11-19},
  abstract = {Contains model-based treatment of missing data for regression  models with missing values in covariates or the dependent  variable using maximum likelihood or Bayesian estimation  (Ibrahim et al., 2005; {$<$}doi:10.1198/016214504000001844{$>$}; Luedtke, Robitzsch, \& West, 2020a, 2020b; {$<$}doi:10.1080/00273171.2019.1640104{$><$}doi:10.1037/met0000233{$>$}). The regression model can be nonlinear (e.g., interaction  effects, quadratic effects or B-spline functions).  Multilevel models with missing data in predictors are available for Bayesian estimation. Substantive-model compatible  multiple imputation can be also conducted.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\UUHCCL9E\Alexander Robitzsch [aut, cre], Oliver Luedtke [aut] - 2017 - mdmb Model Based Treatment of Missing Data.pdf}
}

@article{barnardSmallsampleDegreesFreedom,
  title = {Small-Sample Degrees of Freedom with Multiple Imputation},
  author = {Barnard, John},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\M9DJR6IA\Barnard - Small-sample degrees of freedom with multiple imputation.pdf}
}

@article{elffMultilevelAnalysisFew2021,
  title = {Multilevel {{Analysis}} with {{Few Clusters}}: {{Improving Likelihood-Based Methods}} to {{Provide Unbiased Estimates}} and {{Accurate Inference}}},
  shorttitle = {Multilevel {{Analysis}} with {{Few Clusters}}},
  author = {Elff, Martin and Heisig, Jan Paul and Schaeffer, Merlin and Shikano, Susumu},
  year = 2021,
  month = jan,
  journal = {British Journal of Political Science},
  volume = {51},
  number = {1},
  pages = {412--426},
  issn = {0007-1234, 1469-2112},
  doi = {10.1017/S0007123419000097},
  urldate = {2025-08-13},
  abstract = {Abstract                            Quantitative comparative social scientists have long worried about the performance of multilevel models when the number of upper-level units is small. Adding to these concerns, an influential Monte Carlo study by Stegmueller (2013) suggests that standard maximum-likelihood (ML) methods yield biased point estimates and severely anti-conservative inference with few upper-level units. In this article, the authors seek to rectify this negative assessment. First, they show that ML estimators of coefficients are unbiased in linear multilevel models. The apparent bias in coefficient estimates found by Stegmueller can be attributed to Monte Carlo Error and a flaw in the design of his simulation study. Secondly, they demonstrate how inferential problems can be overcome by using               restricted               ML estimators for variance parameters and a               t               -distribution with appropriate degrees of freedom for statistical inference. Thus, accurate multilevel analysis is possible within the framework that most practitioners are familiar with, even if there are only a few upper-level units.},
  copyright = {http://creativecommons.org/licenses/by-nc-sa/4.0/},
  langid = {english},
  keywords = {degrees of freedom,ML,multilevel,REML,small sample size,t-distribution},
  file = {C:\Users\lonaf\Zotero\storage\WT4QZ4XY\Elff et al. - 2021 - Multilevel Analysis with Few Clusters Improving Likelihood-Based Methods to Provide Unbiased Estima.pdf}
}

@book{endersAppliedMissingData2022,
  title = {Applied {{Missing Data Analysis}}},
  author = {Enders, Craig K},
  year = 2022,
  series = {Methodology in the Social Sciences},
  edition = {2nd ed},
  publisher = {Guilford Press},
  address = {New York},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\8VV9SGX7\Enders - Applied Missing Data Analysis, Second Edition.pdf}
}

@article{endersMissingDataUpdate2025,
  title = {Missing Data: {{An}} Update on the State of the Art.},
  shorttitle = {Missing Data},
  author = {Enders, Craig K.},
  year = 2025,
  month = apr,
  journal = {Psychological Methods},
  volume = {30},
  number = {2},
  pages = {322--339},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000563},
  urldate = {2025-10-23},
  abstract = {Missing data is a common problem in behavioral science research. In 2002, a highly influential paper was published in Psychological Methods that detailed the ``state of the art'' methods for dealing with this issue at the time. Much has changed since then, as missing data methodologies have continually evolved and improved; the range of applications that are now possible has increased dramatically, and software options are far ahead of where they were. This article provides an update on the state of the art that catalogs important innovations from the last two decades of missing data research.},
  copyright = {http://www.apa.org/pubs/journals/resources/open-access.aspx},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\CSWTEKGS\Enders - 2025 - Missing data An update on the state of the art..pdf}
}

@article{endersModelbasedImputationProcedure2020,
  title = {A Model-Based Imputation Procedure for Multilevel Regression Models with Random Coefficients, Interaction Effects, and Nonlinear Terms.},
  author = {Enders, Craig K. and Du, Han and Keller, Brian T.},
  year = 2020,
  month = feb,
  journal = {Psychological Methods},
  volume = {25},
  number = {1},
  pages = {88--112},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000228},
  urldate = {2025-10-23},
  abstract = {Despite the broad appeal of missing data handling approaches that assume a missing at random (MAR) mechanism (e.g., multiple imputation and maximum likelihood estimation), some very common analysis models in the behavioral science literature are known to cause bias-inducing problems for these approaches. Regression models with incomplete interactive or polynomial effects are a particularly important example because they are among the most common analyses in behavioral science research applications. In the context of single-level regression, fully Bayesian (model-based) imputation approaches have shown great promise with these popular analysis models. The purpose of this article is to extend model-based imputation to multilevel models with up to 3 levels, including functionality for mixtures of categorical and continuous variables. Computer simulation results suggest that this new approach can be quite effective when applied to multilevel models with random coefficients and interaction effects. In most scenarios that we examined, imputation-based parameter estimates were quite accurate and tracked closely with those of the complete data. The new procedure is available in the Blimp software application for macOS, Windows, and Linux, and the article includes a data analysis example illustrating its use.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\MLBTTTAB\Enders et al. - 2020 - A model-based imputation procedure for multilevel regression models with random coefficients, intera.pdf}
}

@article{endersMultilevelMultipleImputation2016,
  title = {Multilevel Multiple Imputation: {{A}} Review and Evaluation of Joint Modeling and Chained Equations Imputation.},
  shorttitle = {Multilevel Multiple Imputation},
  author = {Enders, Craig K. and Mistler, Stephen A. and Keller, Brian T.},
  year = 2016,
  month = jun,
  journal = {Psychological Methods},
  volume = {21},
  number = {2},
  pages = {222--240},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000063},
  urldate = {2025-09-05},
  abstract = {Although missing data methods have advanced in recent years, methodologists have devoted less attention to multilevel data structures where observations at level-1 are nested within higher-order organizational units at level-2 (e.g., individuals within neighborhoods; repeated measures nested within individuals; students nested within classrooms). Joint modeling and chained equations imputation are the principal imputation frameworks for single-level data, and both have multilevel counterparts. These approaches differ algorithmically and in their functionality; both are appropriate for simple random intercept analyses with normally distributed data, but they differ beyond that. The purpose of this paper is to describe multilevel imputation strategies and evaluate their performance in a variety of common analysis models. Using multiple imputation theory and computer simulations, we derive 4 major conclusions: (a) joint modeling and chained equations imputation are appropriate for random intercept analyses; (b) the joint model is superior for analyses that posit different within- and between-cluster associations (e.g., a multilevel regression model that includes a level-1 predictor and its cluster means, a multilevel structural equation model with different path values at level-1 and level-2); (c) chained equations imputation provides a dramatic improvement over joint modeling in random slope analyses; and (d) a latent variable formulation for categorical variables is quite effective. We use a real data analysis to demonstrate multilevel imputation, and we suggest a number of avenues for future research.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\W8XLUX9E\Enders et al. - 2016 - Multilevel multiple imputation A review and evaluation of joint modeling and chained equations impu.pdf}
}

@article{erlerDealingMissingCovariates2016,
  title = {Dealing with Missing Covariates in Epidemiologic Studies: A Comparison between Multiple Imputation and a Full {{Bayesian}} Approach},
  shorttitle = {Dealing with Missing Covariates in Epidemiologic Studies},
  author = {Erler, Nicole S. and Rizopoulos, Dimitris and Rosmalen, Joost Van and Jaddoe, Vincent W. V. and Franco, Oscar H. and Lesaffre, Emmanuel M. E. H.},
  year = 2016,
  month = jul,
  journal = {Statistics in Medicine},
  volume = {35},
  number = {17},
  pages = {2955--2974},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.6944},
  urldate = {2025-11-05},
  abstract = {Incomplete data are generally a challenge to the analysis of most large studies. The current gold standard to account for missing data is multiple imputation, and more specifically multiple imputation with chained equations (MICE). Numerous studies have been conducted to illustrate the performance of MICE for missing covariate data. The results show that the method works well in various situations. However, less is known about its performance in more complex models, specifically when the outcome is multivariate as in longitudinal studies. In current practice, the multivariate nature of the longitudinal outcome is often neglected in the imputation procedure, or only the baseline outcome is used to impute missing covariates. In this work, we evaluate the performance of MICE using different strategies to include a longitudinal outcome into the imputation models and compare it with a fully Bayesian approach that jointly imputes missing values and estimates the parameters of the longitudinal model. Results from simulation and a real data example show that MICE requires the analyst to correctly specify which components of the longitudinal process need to be included in the imputation models in order to obtain unbiased results. The full Bayesian approach, on the other hand, does not require the analyst to explicitly specify how the longitudinal outcome enters the imputation models. It performed well under different scenarios. Copyright \copyright{} 2016 John Wiley \& Sons, Ltd.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\IENC3B6H\Erler et al. - 2016 - Dealing with missing covariates in epidemiologic studies a comparison between multiple imputation a.pdf}
}

@article{grahamHowManyImputations2007,
  title = {How {{Many Imputations}} Are {{Really Needed}}? {{Some Practical Clarifications}} of {{Multiple Imputation Theory}}},
  shorttitle = {How {{Many Imputations}} Are {{Really Needed}}?},
  author = {Graham, John W. and Olchowski, Allison E. and Gilreath, Tamika D.},
  year = 2007,
  month = aug,
  journal = {Prevention Science},
  volume = {8},
  number = {3},
  pages = {206--213},
  issn = {1389-4986, 1573-6695},
  doi = {10.1007/s11121-007-0070-9},
  urldate = {2025-11-05},
  abstract = {Multiple imputation (MI) and full information maximum likelihood (FIML) are the two most common approaches to missing data analysis. In theory, MI and FIML are equivalent when identical models are tested using the same variables, and when m, the number of imputations performed with MI, approaches infinity. However, it is important to know how many imputations are necessary before MI and FIML are sufficiently equivalent in ways that are important to prevention scientists. MI theory suggests that small values of m, even on the order of three to five imputations, yield excellent results. Previous guidelines for sufficient m are based on relative efficiency, which involves the fraction of missing information ({$\gamma$}) for the parameter being estimated, and m. In the present study, we used a Monte Carlo simulation to test MI models across several scenarios in which {$\gamma$} and m were varied. Standard errors and p-values for the regression coefficient of interest varied as a function of m, but not at the same rate as relative efficiency. Most importantly, statistical power for small effect sizes diminished as m became smaller, and the rate of this power falloff was much greater than predicted by changes in relative efficiency. Based our findings, we recommend that researchers using MI should perform many more imputations than previously considered sufficient. These recommendations are based on {$\gamma$}, and take into consideration one's tolerance for a preventable power falloff (compared to FIML) due to using too few imputations.},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\6LN9LYJK\Graham et al. - 2007 - How Many Imputations are Really Needed Some Practical Clarifications of Multiple Imputation Theory.pdf}
}

@article{grahamMissingDataAnalysis2009,
  title = {Missing {{Data Analysis}}: {{Making It Work}} in the {{Real World}}},
  shorttitle = {Missing {{Data Analysis}}},
  author = {Graham, John W.},
  year = 2009,
  month = jan,
  journal = {Annual Review of Psychology},
  volume = {60},
  number = {1},
  pages = {549--576},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev.psych.58.110405.085530},
  urldate = {2025-09-05},
  abstract = {This review presents a practical summary of the missing data literature, including a sketch of missing data theory and descriptions of normalmodel multiple imputation (MI) and maximum likelihood methods. Practical missing data analysis issues are discussed, most notably the inclusion of auxiliary variables for improving power and reducing bias. Solutions are given for missing data challenges such as handling longitudinal, categorical, and clustered data with normal-model MI; including interactions in the missing data model; and handling large numbers of variables. The discussion of attrition and nonignorable missingness emphasizes the need for longitudinal diagnostics and for reducing the uncertainty about the missing data mechanism under attrition. Strategies suggested for reducing attrition bias include using auxiliary variables, collecting follow-up data on a sample of those initially missing, and collecting data on intent to drop out. Suggestions are given for moving forward with research on missing data and attrition.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\HEMBQR7G\Graham - 2009 - Missing Data Analysis Making It Work in the Real World.pdf}
}

@misc{grundMitmlToolsMultiple2015,
  title = {Mitml: {{Tools}} for {{Multiple Imputation}} in {{Multilevel Modeling}}},
  shorttitle = {Mitml},
  author = {Grund, Simon and Robitzsch, Alexander and Luedtke, Oliver},
  year = 2015,
  month = may,
  pages = {0.4-5},
  publisher = {Comprehensive R Archive Network},
  doi = {10.32614/CRAN.package.mitml},
  urldate = {2025-11-11},
  abstract = {Provides tools for multiple imputation of missing data in multilevel modeling. Includes a user-friendly interface to the packages 'pan' and 'jomo', and several functions for visualization, data management and the analysis  of multiply imputed data sets.},
  langid = {english}
}

@article{grundMultipleImputationMissing2018,
  title = {Multiple {{Imputation}} of {{Missing Data}} for {{Multilevel Models}}: {{Simulations}} and {{Recommendations}}},
  shorttitle = {Multiple {{Imputation}} of {{Missing Data}} for {{Multilevel Models}}},
  author = {Grund, Simon and L{\"u}dtke, Oliver and Robitzsch, Alexander},
  year = 2018,
  month = jan,
  journal = {Organizational Research Methods},
  volume = {21},
  number = {1},
  pages = {111--149},
  issn = {1094-4281, 1552-7425},
  doi = {10.1177/1094428117703686},
  urldate = {2025-09-05},
  abstract = {Multiple imputation (MI) is one of the principled methods for dealing with missing data. In addition, multilevel models have become a standard tool for analyzing the nested data structures that result when lower level units (e.g., employees) are nested within higher level collectives (e.g., work groups). When applying MI to multilevel data, it is important that the imputation model takes the multilevel structure into account. In the present paper, based on theoretical arguments and computer simulations, we provide guidance using MI in the context of several classes of multilevel models, including models with random intercepts, random slopes, cross-level interactions (CLIs), and missing data in categorical and group-level variables. Our findings suggest that, oftentimes, several approaches to MI provide an effective treatment of missing data in multilevel research. Yet we also note that the current implementations of MI still have room for improvement when handling missing data in explanatory variables in models with random slopes and CLIs. We identify areas for future research and provide recommendations for research practice along with a number of step-bystep examples for the statistical software R.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\ZUXR8SDZ\Grund et al. - 2018 - Multiple Imputation of Missing Data for Multilevel Models Simulations and Recommendations.pdf}
}

@article{grundMultipleImputationMissing2021,
  title = {Multiple Imputation of Missing Data in Multilevel Models with the {{R}} Package Mdmb: A Flexible Sequential Modeling Approach},
  shorttitle = {Multiple Imputation of Missing Data in Multilevel Models with the {{R}} Package Mdmb},
  author = {Grund, Simon and L{\"u}dtke, Oliver and Robitzsch, Alexander},
  year = 2021,
  month = may,
  journal = {Behavior Research Methods},
  volume = {53},
  number = {6},
  pages = {2631--2649},
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01530-0},
  urldate = {2025-11-06},
  abstract = {Abstract             Multilevel models often include nonlinear effects, such as random slopes or interaction effects. The estimation of these models can be difficult when the underlying variables contain missing data. Although several methods for handling missing data such as multiple imputation (MI) can be used with multilevel data, conventional methods for multilevel MI often do not properly take the nonlinear associations between the variables into account. In the present paper, we propose a sequential modeling approach based on Bayesian estimation techniques that can be used to handle missing data in a variety of multilevel models that involve nonlinear effects. The main idea of this approach is to decompose the joint distribution of the data into several parts that correspond to the outcome and explanatory variables in the intended analysis, thus generating imputations in a manner that is compatible with the substantive analysis model. In three simulation studies, we evaluate the sequential modeling approach and compare it with conventional as well as other substantive-model-compatible approaches to multilevel MI. We implemented the sequential modeling approach in the R package  and provide a worked example to illustrate its application.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\R7WJKFMV\Grund et al. - 2021 - Multiple imputation of missing data in multilevel models with the R package mdmb a flexible sequent.pdf}
}

@article{grundMultipleImputationMultilevel2016,
  title = {Multiple {{Imputation}} of {{Multilevel Missing Data}}: {{An Introduction}} to the {{R Package}} Pan},
  shorttitle = {Multiple {{Imputation}} of {{Multilevel Missing Data}}},
  author = {Grund, Simon and L{\"u}dtke, Oliver and Robitzsch, Alexander},
  year = 2016,
  month = oct,
  journal = {Sage Open},
  volume = {6},
  number = {4},
  pages = {2158244016668220},
  issn = {2158-2440, 2158-2440},
  doi = {10.1177/2158244016668220},
  urldate = {2025-09-05},
  abstract = {The treatment of missing data can be difficult in multilevel research because state-of-the-art procedures such as multiple imputation (MI) may require advanced statistical knowledge or a high degree of familiarity with certain statistical software. In the missing data literature, pan has been recommended for MI of multilevel data. In this article, we provide an introduction to MI of multilevel missing data using the R package pan, and we discuss its possibilities and limitations in accommodating typical questions in multilevel research. To make pan more accessible to applied researchers, we make use of the mitml package, which provides a user-friendly interface to the pan package and several tools for managing and analyzing multiply imputed data sets. We illustrate the use of pan and mitml with two empirical examples that represent common applications of multilevel models, and we discuss how these procedures may be used in conjunction with other software.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\RX3IK78K\Grund et al. - 2016 - Multiple Imputation of Multilevel Missing Data An Introduction to the R Package pan.pdf}
}

@article{ibrahimBayesianMethodsGeneralized2002,
  title = {Bayesian Methods for Generalized Linear Models with Covariates Missing at Random},
  author = {Ibrahim, Joseph G. and Chen, Ming-Hui and Lipsitz, Stuart R.},
  year = 2002,
  month = mar,
  journal = {Canadian Journal of Statistics},
  volume = {30},
  number = {1},
  pages = {55--78},
  issn = {0319-5724, 1708-945X},
  doi = {10.2307/3315865},
  urldate = {2025-11-05},
  abstract = {Abstract             The authors propose methods for Bayesian inference for generalized linear models with missing covariate data. They specify a parametric distribution for the covariates that is written as a sequence of one-dimensional conditional distributions. They propose an informative class of joint prior distributions for the regression coefficients and the parameters arising from the covariate distributions. They examine the properties of the proposed prior and resulting posterior distributions. They also present a Bayesian criterion for comparing various models, and a calibration is derived for it. A detailed simulation is conducted and two real data sets are examined to demonstrate the methodology.           ,                             M\'ethodes bay\'esiennes pour mod\`eles lin\'eaires g\'en\'eralis\'es dont certaines valeurs des covariables sont manquantes de fa\c con fortuite                          Les auteurs proposent des m\'ethodes d'inf\'erence bay\'esienne adapt\'ees aux mod\`eles lin\'eaires g\'en\'e-ralis\'es pour les situations o\`u les valeurs de certaines covariables sont manquantes au hasard. La loi param\'etrique choisie pour les covariables s'exprime comme succession de lois conditionnelles univari\'ees. Une classe de lois a priori informative est sugg\'er\'ee pour les coefficients de r\'egression et pour les param\`etres li\'es aux lois des covariables. Les auteurs examinent les propri\'et\'es de ces lois a priori et des lois a posteriori qui en d\'ecoulent. Ils pr\'esentent aussi un crit\`ere bay\'esien pour la comparaison des diff\'erents mod\`eles et montrent comment le calibrer. Une simulation d\'etaill\'ee et l'examen de deux ensembles de donn\'ees r\'eelles illustrent l'approche propos\'ee.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\J8MZXI5I\Ibrahim et al. - 2002 - Bayesian methods for generalized linear models with covariates missing at random.pdf}
}

@book{kleinkeAppliedMultipleImputation2020,
  title = {Applied {{Multiple Imputation}}: {{Advantages}}, {{Pitfalls}}, {{New Developments}} and {{Applications}} in {{R}}},
  shorttitle = {Applied {{Multiple Imputation}}},
  author = {Kleinke, Kristian and Reinecke, Jost and Salfr{\'a}n, Daniel and Spiess, Martin},
  year = 2020,
  series = {Statistics for {{Social}} and {{Behavioral Sciences}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-38164-6},
  urldate = {2025-11-05},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-030-38163-9 978-3-030-38164-6},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\Z45J3PH6\Kleinke et al. - 2020 - Applied Multiple Imputation Advantages, Pitfalls, New Developments and Applications in R.pdf}
}

@article{liComparingDenominatorDegrees2015,
  title = {Comparing Denominator Degrees of Freedom Approximations for the Generalized Linear Mixed Model in Analyzing Binary Outcome in Small Sample Cluster-Randomized Trials},
  author = {Li, Peng and Redden, David T},
  year = 2015,
  month = dec,
  journal = {BMC Medical Research Methodology},
  volume = {15},
  number = {1},
  pages = {38},
  issn = {1471-2288},
  doi = {10.1186/s12874-015-0026-x},
  urldate = {2025-09-05},
  abstract = {Background: Small number of clusters and large variation of cluster sizes commonly exist in cluster-randomized trials (CRTs) and are often the critical factors affecting the validity and efficiency of statistical analyses. F tests are commonly used in the generalized linear mixed model (GLMM) to test intervention effects in CRTs. The most challenging issue for the approximate Wald F test is the estimation of the denominator degrees of freedom (DDF). Some DDF approximation methods have been proposed, but their small sample performances in analysing binary outcomes in CRTs with few heterogeneous clusters are not well studied. Methods: The small sample performances of five DDF approximations for the F test are compared and contrasted under CRT frameworks with simulations. Specifically, we illustrate how the intraclass correlation (ICC), sample size, and the variation of cluster sizes affect the type I error and statistical power when different DDF approximation methods in GLMM are used to test intervention effect in CRTs with binary outcomes. The results are also illustrated using a real CRT dataset. Results: Our simulation results suggest that the Between-Within method maintains the nominal type I error rates even when the total number of clusters is as low as 10 and is robust to the variation of the cluster sizes. The Residual and Containment methods have inflated type I error rates when the cluster number is small ({$<$}30) and the inflation becomes more severe with increased variation in cluster sizes. In contrast, the Satterthwaite and Kenward-Roger methods can provide tests with very conservative type I error rates when the total cluster number is small ({$<$}30) and the conservativeness becomes more severe as variation in cluster sizes increases. Our simulations also suggest that the Between-Within method is statistically more powerful than the Satterthwaite or Kenward-Roger method in analysing CRTs with heterogeneous cluster sizes, especially when the cluster number is small. Conclusion: We conclude that the Between-Within denominator degrees of freedom approximation method for F tests should be recommended when the GLMM is used in analysing CRTs with binary outcomes and few heterogeneous clusters, due to its type I error properties and relatively higher power.},
  langid = {english},
  keywords = {degrees of freedom,Einschrankung Kenward-Rogers,schwer},
  file = {C:\Users\lonaf\Zotero\storage\57R2LRFA\Li und Redden - 2015 - Comparing denominator degrees of freedom approximations for the generalized linear mixed model in an.pdf}
}

@article{ludtkeRegressionModelsInvolving2020,
  title = {Regression Models Involving Nonlinear Effects with Missing Data: {{A}} Sequential Modeling Approach Using {{Bayesian}} Estimation.},
  shorttitle = {Regression Models Involving Nonlinear Effects with Missing Data},
  author = {L{\"u}dtke, Oliver and Robitzsch, Alexander and West, Stephen G.},
  year = 2020,
  month = apr,
  journal = {Psychological Methods},
  volume = {25},
  number = {2},
  pages = {157--181},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000233},
  urldate = {2025-11-05},
  abstract = {When estimating multiple regression models with incomplete predictor variables, it is necessary to specify a joint distribution for the predictor variables. A convenient assumption is that this distribution is a joint normal distribution, the default in many statistical software packages. This distribution will in general be misspecified if the predictors with missing data have nonlinear effects (e.g., x2) or are included in interaction terms (e.g., x {$\cdot$} z). In the present article, we discuss a sequential modeling approach that can be applied to decompose the joint distribution of the variables into 2 parts: (a) a part that is due to the model of interest and (b) a part that is due to the model for the incomplete predictors. We demonstrate how the sequential modeling approach can be used to implement a multiple imputation strategy based on Bayesian estimation techniques that can accommodate rather complex substantive regression models with nonlinear effects and also allows a flexible treatment of auxiliary variables. In 4 simulation studies, we showed that the sequential modeling approach can be applied to estimate nonlinear effects in regression models with missing values on continuous, categorical, or skewed predictor variables under a broad range of conditions and investigated the robustness of the proposed approach against distributional misspecifications. We developed the R package mdmb, which facilitates a user-friendly application of the sequential modeling approach, and we present a real-data example that illustrates the flexibility of the software.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\A4B6XEMN\Lüdtke et al. - 2020 - Regression models involving nonlinear effects with missing data A sequential modeling approach usin.pdf}
}

@article{luedtkeUmgangMitFehlenden2007,
  title = {{Umgang mit fehlenden Werten in der psychologischen Forschung}},
  author = {L{\"u}dtke, Oliver and Robitzsch, Alexander and Trautwein, Ulrich and K{\"o}ller, Olaf},
  year = 2007,
  month = apr,
  journal = {Psychologische Rundschau},
  volume = {58},
  number = {2},
  pages = {103--117},
  issn = {0033-3042, 2190-6238},
  doi = {10.1026/0033-3042.58.2.103},
  urldate = {2025-09-05},
  abstract = {Missing data are a pervasive problem in empirical psychological research. From the methodological perspective, traditional procedures such as Casewise and Pairwise Deletion, Regression Imputation, and Mean Imputation have distinct weaknesses. Yet modern statistical methods for the analysis of datasets with missing values that have been developed in the past three decades have not yet gained a significant foothold in research practice. We begin this article by introducing the basic concepts and terminology of missing data, as proposed by Rubin (1976). We then give an overview of the different approaches to handling missing data discussed in the literature, distinguishing between three types of procedures: traditional procedures (e.g., Listwise Deletion), imputation-based procedures, in which missing values are replaced by imputed values, and model-based procedures, in which models are estimated and missing data handled in a single step. In the empirical section of the article, we demonstrate the application of Multiple Imputation using a dataset from a large-scale educational assessment. Implications for research practice are discussed.},
  langid = {ngerman},
  file = {C:\Users\lonaf\Zotero\storage\ZJMA4KYQ\Lüdtke et al. - 2007 - Umgang mit fehlenden Werten in der psychologischen Forschung.pdf}
}

@article{mcneishModelingClusteredData2016,
  title = {Modeling {{Clustered Data}} with {{Very Few Clusters}}},
  author = {McNeish, Daniel and Stapleton, Laura M.},
  year = 2016,
  month = jul,
  journal = {Multivariate Behavioral Research},
  volume = {51},
  number = {4},
  pages = {495--518},
  issn = {0027-3171, 1532-7906},
  doi = {10.1080/00273171.2016.1167008},
  urldate = {2025-09-05},
  abstract = {Small-sample inference with clustered data has received increased attention recently in the methodological literature, with several simulation studies being presented on the small-sample behavior of many methods. However, nearly all previous studies focus on a single class of methods (e.g., only multilevel models, only corrections to sandwich estimators), and the differential performance of various methods that can be implemented to accommodate clustered data with very few clusters is largely unknown, potentially due to the rigid disciplinary preferences. Furthermore, a majority of these studies focus on scenarios with 15 or more clusters and feature unrealistically simple data-generation models with very few predictors. This article, motivated by an applied educational psychology cluster randomized trial, presents a simulation study that simultaneously addresses the extreme small sample and differential performance (estimation bias, Type I error rates, and relative power) of 12 methods to account for clustered data with a model that features a more realistic number of predictors. The motivating data are then modeled with each method, and results are compared. Results show that generalized estimating equations perform poorly; the choice of Bayesian prior distributions affects performance; and fixed effect models perform quite well. Limitations and implications for applications are also discussed.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\TVIWFYG2\McNeish und Stapleton - 2016 - Modeling Clustered Data with Very Few Clusters.pdf}
}

@article{mcneishSmallSampleMethods2017,
  title = {Small {{Sample Methods}} for {{Multilevel Modeling}}: {{A Colloquial Elucidation}} of {{REML}} and the {{Kenward-Roger Correction}}},
  shorttitle = {Small {{Sample Methods}} for {{Multilevel Modeling}}},
  author = {McNeish, Daniel},
  year = 2017,
  month = sep,
  journal = {Multivariate Behavioral Research},
  volume = {52},
  number = {5},
  pages = {661--670},
  issn = {0027-3171, 1532-7906},
  doi = {10.1080/00273171.2017.1344538},
  urldate = {2025-11-05},
  abstract = {Studies on small sample properties of multilevel models have become increasingly prominent in the methodological literature in response to the frequency with which small sample data appear in empirical studies. Simulation results generally recommend that empirical researchers employ restricted maximum likelihood estimation (REML) with a Kenward-Roger correction with small samples in frequentist contexts to minimize small sample bias in estimation and to prevent inflation of Type-I error rates. However , simulation studies focus on recommendations for best practice, and there is little to no explanation of why traditional maximum likelihood (ML) breaks down with smaller samples, what differentiates REML from ML, or how the Kenward-Roger correction remedies lingering small sample issues. Due to the complexity of these methods, most extant descriptions are highly mathematical and are intended to prove that the methods improve small sample performance as intended. Thus, empirical researchers have documentation that these methods are advantageous but still lack resources to help understand what the methods actually do and why they are needed. This tutorial explains why ML falters with small samples, how REML circumvents some issues, and how Kenward-Roger works. We do so without equations or derivations to support more widespread understanding and use of these valuable methods.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\YZ8Q3KX5\McNeish - 2017 - Small Sample Methods for Multilevel Modeling A Colloquial Elucidation of REML and the Kenward-Roger.pdf}
}

@article{morrisUsingSimulationStudies2019,
  title = {Using Simulation Studies to Evaluate Statistical Methods},
  author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
  year = 2019,
  month = may,
  journal = {Statistics in Medicine},
  volume = {38},
  number = {11},
  pages = {2074--2102},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.8086},
  urldate = {2025-11-05},
  abstract = {Simulation studies are computer experiments that involve creating data by pseudo-random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods because some ``truth'' (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analyzed, and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting, and presentation. In particular, this tutorial provides a structured approach for planning and reporting simulation studies, which involves defining aims, data-generating mechanisms, estimands, methods, and performance measures (``ADEMP''); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume~34 of               Statistics in Medicine               , which included at least one simulation study and identify areas for improvement.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\IWMQEHAW\Morris et al. - 2019 - Using simulation studies to evaluate statistical methods.pdf}
}

@misc{quartagnoJomoMultilevelJoint2014,
  title = {Jomo: {{Multilevel Joint Modelling Multiple Imputation}}},
  shorttitle = {Jomo},
  author = {Quartagno, Matteo and Carpenter, James},
  year = 2014,
  month = dec,
  pages = {2.7-6},
  publisher = {Comprehensive R Archive Network},
  doi = {10.32614/CRAN.package.jomo},
  urldate = {2025-11-13},
  abstract = {Similarly to package 'pan', 'jomo' is a package for multilevel joint modelling multiple imputation (Carpenter and Kenward, 2013) {$<$}doi:10.1002/9781119942283{$>$}. Novel aspects of 'jomo' are the possibility of handling binary and categorical data through latent normal variables, the option to use cluster-specific covariance matrices and to impute compatibly with the substantive model.},
  langid = {english}
}

@misc{robitzschMdmbModelBased2017,
  title = {Mdmb: {{Model Based Treatment}} of {{Missing Data}}},
  shorttitle = {Mdmb},
  author = {Robitzsch, Alexander and Luedtke, Oliver},
  year = 2017,
  month = jan,
  pages = {1.9-22},
  publisher = {Comprehensive R Archive Network},
  doi = {10.32614/CRAN.package.mdmb},
  urldate = {2025-11-11},
  abstract = {Contains model-based treatment of missing data for regression  models with missing values in covariates or the dependent  variable using maximum likelihood or Bayesian estimation  (Ibrahim et al., 2005; {$<$}doi:10.1198/016214504000001844{$>$}; Luedtke, Robitzsch, \& West, 2020a, 2020b; {$<$}doi:10.1080/00273171.2019.1640104{$><$}doi:10.1037/met0000233{$>$}). The regression model can be nonlinear (e.g., interaction  effects, quadratic effects or B-spline functions).  Multilevel models with missing data in predictors are available for Bayesian estimation. Substantive-model compatible  multiple imputation can be also conducted.},
  langid = {english}
}

@book{rubinMultipleImputationNonresponse1987,
  title = {Multiple Imputation for Nonresponse in Surveys},
  author = {Rubin, Donald B.},
  year = 1987,
  series = {Wiley Series in Probability and Mathematical Statistics {{Applied}} Probability and Statistics},
  publisher = {Wiley},
  address = {New York},
  doi = {10.1002/9780470316696},
  isbn = {9780471087052 9780470317365 9780470316696 9786612307591},
  langid = {english}
}

@article{schaaljeAdequacyApproximationsDistributions2002,
  title = {Adequacy of Approximations to Distributions of Test Statistics in Complex Mixed Linear Models},
  author = {Schaalje, G. Bruce and McBride, Justin B. and Fellingham, Gilbert W.},
  year = 2002,
  month = dec,
  journal = {Journal of Agricultural, Biological, and Environmental Statistics},
  volume = {7},
  number = {4},
  pages = {512--524},
  issn = {1085-7117, 1537-2693},
  doi = {10.1198/108571102726},
  urldate = {2025-09-05},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\DNUUMAQT\Schaalje et al. - 2002 - Adequacy of approximations to distributions of test statistics in complex mixed linear models.pdf}
}

@article{schaferMissingDataOur2002,
  title = {Missing Data: {{Our}} View of the State of the Art.},
  shorttitle = {Missing Data},
  author = {Schafer, Joseph L. and Graham, John W.},
  year = 2002,
  journal = {Psychological Methods},
  volume = {7},
  number = {2},
  pages = {147--177},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/1082-989X.7.2.147},
  urldate = {2025-09-05},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\P6I33SHP\Schafer und Graham - 2002 - Missing data Our view of the state of the art..pdf}
}

@article{siepeSimulationStudiesMethodological2024,
  title = {Simulation Studies for Methodological Research in Psychology: {{A}} Standardized Template for Planning, Preregistration, and Reporting.},
  shorttitle = {Simulation Studies for Methodological Research in Psychology},
  author = {Siepe, Bj{\"o}rn S. and Barto{\v s}, Franti{\v s}ek and Morris, Tim P. and Boulesteix, Anne-Laure and Heck, Daniel W. and Pawel, Samuel},
  year = 2024,
  month = nov,
  journal = {Psychological Methods},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000695},
  urldate = {2025-09-05},
  abstract = {Simulation studies are widely used for evaluating the performance of statistical methods in psychology. However, the quality of simulation studies can vary widely in terms of their design, execution, and reporting. In order to assess the quality of typical simulation studies in psychology, we reviewed 321 articles published in Psychological Methods, Behavior Research Methods, and Multivariate Behavioral Research in 2021 and 2022, among which 100/321 = 31.2\% report a simulation study. We find that many articles do not provide complete and transparent information about key aspects of the study, such as justifications for the number of simulation repetitions, Monte Carlo uncertainty estimates, or code and data to reproduce the simulation studies. To address this problem, we provide a summary of the ADEMP (aims, data-generating mechanism, estimands and other targets, methods, performance measures) design and reporting framework from Morris et al. (2019) adapted to simulation studies in psychology. Based on this framework, we provide ADEMP-PreReg, a step-by-step template for researchers to use when designing, potentially preregistering, and reporting their simulation studies. We give formulae for estimating common performance measures, their Monte Carlo standard errors, and for calculating the number of simulation repetitions to achieve a desired Monte Carlo standard error. Finally, we give a detailed tutorial on how to apply the ADEMP framework in practice using an example simulation study on the evaluation of methods for the analysis of pre--post measurement experiments.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\GLKZSMYD\Siepe et al. - 2024 - Simulation studies for methodological research in psychology A standardized template for planning,.pdf}
}

@misc{simongrund[autcre]alexanderrobitzsch[aut]oliverluedtke[aut]MitmlToolsMultiple2015,
  title = {Mitml: {{Tools}} for {{Multiple Imputation}} in {{Multilevel Modeling}}},
  shorttitle = {Mitml},
  author = {{Simon Grund [aut,cre], Alexander Robitzsch [aut], Oliver Luedtke [aut]}},
  year = 2015,
  month = may,
  pages = {0.4-5},
  publisher = {Comprehensive R Archive Network},
  doi = {10.32614/CRAN.package.mitml},
  urldate = {2025-11-19},
  abstract = {Provides tools for multiple imputation of missing data in multilevel modeling. Includes a user-friendly interface to the packages 'pan' and 'jomo', and several functions for visualization, data management and the analysis  of multiply imputed data sets.},
  langid = {english},
  file = {C:\Users\lonaf\Zotero\storage\BRK9PNFQ\Simon Grund [aut,cre], Alexander Robitzsch [aut], Oliver Luedtke [aut] - 2015 - mitml Tools for Multiple Imputation in Multilevel Modeling.pdf}
}

@book{snijdersMultilevelAnalysisIntroduction2012,
  title = {Multilevel Analysis: An Introduction to Basic and Advanced Multilevel Modeling},
  shorttitle = {Multilevel Analysis},
  author = {Snijders, T. A. B. and Bosker, R. J.},
  year = 2012,
  edition = {2nd ed},
  publisher = {Sage},
  address = {Los Angeles},
  isbn = {978-1-84920-200-8},
  langid = {english},
  lccn = {QA278 .S645 2012},
  keywords = {Multivariate analysis},
  file = {C:\Users\lonaf\Zotero\storage\FEGVYHMN\Snijders und Bosker - 2012 - Multilevel analysis an introduction to basic and advanced multilevel modeling.pdf}
}
